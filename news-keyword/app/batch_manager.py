#!/usr/bin/env python3
"""
ë°°ì¹˜ ì²˜ë¦¬ ë§¤ë‹ˆì € ëª¨ë“ˆ
OpenAI API í˜¸ì¶œì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ í† í° ì†Œë¹„ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
import time
import uuid
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict
from enum import Enum

logger = logging.getLogger(__name__)

class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class BatchRequest:
    """ë°°ì¹˜ ì²˜ë¦¬ ìš”ì²­"""
    task_id: str
    company_name: str
    keywords_dict: Dict[str, int]
    max_keywords: int
    start_date: str = ""
    end_date: str = ""
    total_news_count: int = 0
    original_keyword_count: int = 0
    created_at: datetime = field(default_factory=datetime.now)
    
@dataclass
class BatchResult:
    """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼"""
    task_id: str
    status: TaskStatus
    filtered_keywords: Optional[Dict[str, int]] = None
    top_keywords: Optional[List[str]] = None
    error_message: Optional[str] = None
    completed_at: Optional[datetime] = None
    # ì›ë³¸ ìš”ì²­ ì •ë³´ ì €ì¥
    original_request: Optional['BatchRequest'] = None

class BatchKeywordManager:
    """í‚¤ì›Œë“œ ì¶”ì¶œ ë°°ì¹˜ ì²˜ë¦¬ ë§¤ë‹ˆì €"""
    
    def __init__(self, 
                 buffer_time_ms: int = 2000,  # 2ì´ˆ ë²„í¼ (ë” ì§§ê²Œ)
                 max_batch_size: int = 10,    # ë” í° ë°°ì¹˜ í¬ê¸°
                 max_tokens_per_batch: int = 4000):  # ë°°ì¹˜ë‹¹ ìµœëŒ€ í† í°
        """
        ì´ˆê¸°í™”
        
        Args:
            buffer_time_ms: ë²„í¼ ëŒ€ê¸° ì‹œê°„ (ë°€ë¦¬ì´ˆ)
            max_batch_size: ìµœëŒ€ ë°°ì¹˜ í¬ê¸°
            max_tokens_per_batch: ë°°ì¹˜ë‹¹ ìµœëŒ€ í† í° ìˆ˜
        """
        self.buffer_time_ms = buffer_time_ms
        self.max_batch_size = max_batch_size
        self.max_tokens_per_batch = max_tokens_per_batch
        
        # ì²« ìš”ì²­ ì‹œê°„ ì¶”ì 
        self.first_request_time: Optional[datetime] = None
        
        # ìš”ì²­ ë²„í¼
        self.pending_requests: List[BatchRequest] = []
        self.request_lock = asyncio.Lock()
        
        # ê²°ê³¼ ì €ì¥ì†Œ
        self.results: Dict[str, BatchResult] = {}
        self.result_lock = asyncio.Lock()
        
        # ë°°ì¹˜ ì²˜ë¦¬ íƒœìŠ¤í¬
        self.batch_task: Optional[asyncio.Task] = None
        self.is_running = False
        
        # í†µê³„
        self.stats = {
            "total_requests": 0,
            "total_batches": 0,
            "total_tokens_saved": 0,
            "average_batch_size": 0.0
        }
    
    async def start(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ë§¤ë‹ˆì € ì‹œì‘"""
        if self.is_running:
            return
        
        self.is_running = True
        self.batch_task = asyncio.create_task(self._batch_processor())
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ë§¤ë‹ˆì € ì‹œì‘: ë²„í¼ ì‹œê°„ {self.buffer_time_ms}ms, ìµœëŒ€ ë°°ì¹˜ í¬ê¸° {self.max_batch_size}")
    
    async def stop(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ë§¤ë‹ˆì € ì¤‘ì§€"""
        self.is_running = False
        if self.batch_task:
            self.batch_task.cancel()
            try:
                await self.batch_task
            except asyncio.CancelledError:
                pass
        logger.info("ë°°ì¹˜ ì²˜ë¦¬ ë§¤ë‹ˆì € ì¤‘ì§€")
    
    async def submit_request(self, company_name: str, keywords_dict: Dict[str, int], max_keywords: int, 
                           start_date: str = "", end_date: str = "", total_news_count: int = 0) -> str:
        """
        í‚¤ì›Œë“œ í•„í„°ë§ ìš”ì²­ ì œì¶œ
        
        Args:
            company_name: ê¸°ì—…ëª…
            keywords_dict: í‚¤ì›Œë“œ ë”•ì…”ë„ˆë¦¬
            max_keywords: ìµœëŒ€ í‚¤ì›Œë“œ ê°œìˆ˜
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            total_news_count: ì´ ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            str: ì‘ì—… ID
        """
        task_id = str(uuid.uuid4())
        
        request = BatchRequest(
            task_id=task_id,
            company_name=company_name,
            keywords_dict=keywords_dict,
            max_keywords=max_keywords,
            start_date=start_date,
            end_date=end_date,
            total_news_count=total_news_count,
            original_keyword_count=len(keywords_dict)
        )
        
        async with self.request_lock:
            # ì²« ë²ˆì§¸ ìš”ì²­ì´ë©´ ì‹œê°„ ê¸°ë¡
            if not self.pending_requests:
                self.first_request_time = datetime.now()
                logger.info(f"ğŸ• ì²« ë²ˆì§¸ ë°°ì¹˜ ìš”ì²­ ë„ì°©: {company_name}")
            
            self.pending_requests.append(request)
            self.stats["total_requests"] += 1
            
            logger.info(f"ğŸ“¥ ë°°ì¹˜ ìš”ì²­ ì¶”ê°€: {company_name} (ëŒ€ê¸° ì¤‘: {len(self.pending_requests)}ê°œ)")
        
        # ê²°ê³¼ ì €ì¥ì†Œì— ì´ˆê¸° ìƒíƒœ ë“±ë¡
        async with self.result_lock:
            self.results[task_id] = BatchResult(
                task_id=task_id,
                status=TaskStatus.PENDING,
                original_request=request
            )
        
        return task_id
    
    async def get_result(self, task_id: str) -> Optional[BatchResult]:
        """
        ì‘ì—… ê²°ê³¼ ì¡°íšŒ
        
        Args:
            task_id: ì‘ì—… ID
            
        Returns:
            BatchResult: ì‘ì—… ê²°ê³¼ (ì—†ìœ¼ë©´ None)
        """
        async with self.result_lock:
            return self.results.get(task_id)
    
    async def wait_for_result(self, task_id: str, timeout: float = 30.0) -> Optional[BatchResult]:
        """
        ì‘ì—… ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        
        Args:
            task_id: ì‘ì—… ID
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            BatchResult: ì‘ì—… ê²°ê³¼
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            result = await self.get_result(task_id)
            if result and result.status in [TaskStatus.COMPLETED, TaskStatus.FAILED]:
                return result
            
            await asyncio.sleep(0.1)  # 100ms ëŒ€ê¸°
        
        # íƒ€ì„ì•„ì›ƒ
        async with self.result_lock:
            if task_id in self.results:
                existing_result = self.results[task_id]
                self.results[task_id] = BatchResult(
                    task_id=task_id,
                    status=TaskStatus.FAILED,
                    error_message="ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼",
                    completed_at=datetime.now(),
                    original_request=existing_result.original_request
                )
                return self.results[task_id]
        
        return None
    
    async def _batch_processor(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ë©”ì¸ ë£¨í”„ (ë™ì‹œ ìš”ì²­ ìµœì í™”)"""
        while self.is_running:
            try:
                # 0.5ì´ˆë§ˆë‹¤ í™•ì¸ (ë” ë¹ ë¥¸ ë°˜ì‘)
                await asyncio.sleep(3)
                
                # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ë“¤ ìˆ˜ì§‘
                batch_requests = await self._collect_batch_requests()
                
                if batch_requests:
                    logger.info(f"ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(batch_requests)}ê°œ ìš”ì²­ì„ í•˜ë‚˜ì˜ API í˜¸ì¶œë¡œ ì²˜ë¦¬")
                    
                    # ì²« ìš”ì²­ ì‹œê°„ ì´ˆê¸°í™”
                    async with self.request_lock:
                        self.first_request_time = None
                    
                    await self._process_batch(batch_requests)
                    self.stats["total_batches"] += 1
                    self.stats["average_batch_size"] = self.stats["total_requests"] / self.stats["total_batches"]
                    
                    # í† í° ì ˆì•½ ì¶”ì • (ë°°ì¹˜ í¬ê¸° - 1) * í‰ê·  í† í°
                    if len(batch_requests) > 1:
                        estimated_tokens_saved = (len(batch_requests) - 1) * 500  # í‰ê·  500 í† í°ìœ¼ë¡œ ê°€ì •
                        self.stats["total_tokens_saved"] += estimated_tokens_saved
                        logger.info(f"ğŸ’° í† í° ì ˆì•½: +{estimated_tokens_saved} (ì´ ì ˆì•½: {self.stats['total_tokens_saved']})")
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(0.5)  # ì˜¤ë¥˜ ì‹œ ì ì‹œ ëŒ€ê¸°
    
    async def _collect_batch_requests(self) -> List[BatchRequest]:
        """ë°°ì¹˜ ì²˜ë¦¬í•  ìš”ì²­ë“¤ ìˆ˜ì§‘ (ë™ì‹œ ìš”ì²­ ìµœì í™”)"""
        batch_requests = []
        
        async with self.request_lock:
            if not self.pending_requests:
                return batch_requests
            
            current_time = datetime.now()
            
            # ì²« ìš”ì²­ ê¸°ì¤€ìœ¼ë¡œ ê²½ê³¼ ì‹œê°„ ê³„ì‚°
            if self.first_request_time:
                first_elapsed = (current_time - self.first_request_time).total_seconds() * 1000
            else:
                first_elapsed = 0
            
            # ë°°ì¹˜ ì²˜ë¦¬ ì¡°ê±´ (ë” ì ê·¹ì ìœ¼ë¡œ)
            should_process = (
                first_elapsed >= self.buffer_time_ms or  # ì²« ìš”ì²­ë¶€í„° ë²„í¼ ì‹œê°„ ê²½ê³¼
                len(self.pending_requests) >= self.max_batch_size or  # ìµœëŒ€ í¬ê¸° ë„ë‹¬
                (len(self.pending_requests) >= 2 and first_elapsed >= 1000)  # 2ê°œ ì´ìƒì´ê³  1ì´ˆ ê²½ê³¼
            )
            
            if should_process:
                # ëª¨ë“  ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì„ ë°°ì¹˜ë¡œ ìˆ˜ì§‘ (ìµœëŒ€ í¬ê¸°ê¹Œì§€)
                batch_requests = self.pending_requests[:self.max_batch_size]
                self.pending_requests = self.pending_requests[self.max_batch_size:]
                
                company_names = [req.company_name for req in batch_requests]
                logger.info(f"âš¡ ë°°ì¹˜ ìˆ˜ì§‘: {len(batch_requests)}ê°œ ìš”ì²­ [{', '.join(company_names)}], ë‚¨ì€ ìš”ì²­: {len(self.pending_requests)}ê°œ")
                logger.info(f"â±ï¸ ì²« ìš”ì²­ë¶€í„° ê²½ê³¼ ì‹œê°„: {first_elapsed:.0f}ms")
        
        return batch_requests
    
    async def _process_batch(self, batch_requests: List[BatchRequest]):
        """ë°°ì¹˜ ìš”ì²­ë“¤ ì²˜ë¦¬"""
        if not batch_requests:
            return
        
        # ëª¨ë“  ìš”ì²­ì˜ ìƒíƒœë¥¼ PROCESSINGìœ¼ë¡œ ë³€ê²½
        async with self.result_lock:
            for request in batch_requests:
                if request.task_id in self.results:
                    self.results[request.task_id].status = TaskStatus.PROCESSING
        
        try:
            # SmartKeywordFilterë¥¼ ë™ì ìœ¼ë¡œ ì„í¬íŠ¸ (ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€)
            from smart_keyword_filter import SmartKeywordFilter
            
            smart_filter = SmartKeywordFilter()
            
            if not smart_filter.is_available():
                # AI ì‚¬ìš© ë¶ˆê°€ì‹œ ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
                await self._process_batch_individually(batch_requests)
                return
            
            # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì²˜ë¦¬
            batch_response = await self._process_batch_with_ai(smart_filter, batch_requests)
            
            # ì‘ë‹µ íŒŒì‹± ë° ê²°ê³¼ ì €ì¥
            await self._parse_and_save_batch_results(batch_requests, batch_response)
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            await self._mark_batch_as_failed(batch_requests, str(e))
    
    async def _process_batch_individually(self, batch_requests: List[BatchRequest]):
        """ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±"""
        from smart_keyword_filter import SmartKeywordFilter
        
        smart_filter = SmartKeywordFilter()
        
        for request in batch_requests:
            try:
                filtered_keywords, top_keywords = smart_filter.filter_stock_related_keywords(
                    request.keywords_dict,
                    request.company_name,
                    request.max_keywords
                )
                
                async with self.result_lock:
                            self.results[request.task_id] = BatchResult(
                                task_id=request.task_id,
                                status=TaskStatus.COMPLETED,
                                filtered_keywords=filtered_keywords,
                                top_keywords=top_keywords,
                                completed_at=datetime.now(),
                                original_request=request
                            )
                
            except Exception as e:
                async with self.result_lock:
                    self.results[request.task_id] = BatchResult(
                        task_id=request.task_id,
                        status=TaskStatus.FAILED,
                        error_message=str(e),
                        completed_at=datetime.now(),
                        original_request=request
                    )
    
    async def _process_batch_with_ai(self, smart_filter, batch_requests: List[BatchRequest]) -> str:
        """AIë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ì²˜ë¦¬"""
        # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
        batch_prompt = self._create_batch_prompt(batch_requests)
        
        # OpenAI API í˜¸ì¶œ
        response = smart_filter.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë° ì£¼ì‹ ì‹œì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ê¸°ì—…ì˜ ë‰´ìŠ¤ í‚¤ì›Œë“œë“¤ì„ ë™ì‹œì— ë¶„ì„í•˜ì—¬ ê° ê¸°ì—…ë³„ë¡œ ì£¼ê°€ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë§Œì„ ì„ ë³„í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤."},
                {"role": "user", "content": batch_prompt}
            ],
            temperature=0.1,
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
    
    def _create_batch_prompt(self, batch_requests: List[BatchRequest]) -> str:
        """ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt_parts = ["ë‹¤ìŒ ê¸°ì—…ë“¤ì˜ ë‰´ìŠ¤ í‚¤ì›Œë“œë¥¼ ê°ê° ë¶„ì„í•˜ì—¬ ì£¼ê°€ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë§Œ ì„ ë³„í•´ì£¼ì„¸ìš”.\n"]
        
        for i, request in enumerate(batch_requests, 1):
            # ìƒìœ„ 50ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš© (í† í° ì ˆì•½)
            top_keywords = list(request.keywords_dict.keys())[:50]
            keywords_str = ', '.join(top_keywords)
            
            prompt_parts.append(f"\n{i}. {request.company_name}:")
            prompt_parts.append(f"í‚¤ì›Œë“œ: {keywords_str}")
        
        prompt_parts.append("""
ì£¼ê°€ ê´€ë ¨ í‚¤ì›Œë“œ ì„ ë³„ ê¸°ì¤€:
âœ… í¬í•¨í•  í‚¤ì›Œë“œ: ì¬ë¬´/ì‹¤ì , ì‚¬ì—…/íˆ¬ì, ì‹œì¥, ê²½ì˜, ì£¼ì‹ì‹œì¥ ê´€ë ¨
âŒ ì œì™¸í•  í‚¤ì›Œë“œ: ê¸°ì—…ëª… ìì²´, ì¼ë°˜ìš©ì–´, ë‹¨ìˆœ ì œí’ˆëª…, ì§€ì—­ëª…

ì‘ë‹µ í˜•ì‹: ê° ê¸°ì—…ë³„ë¡œ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì„ ë³„ëœ í‚¤ì›Œë“œë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´
ì˜ˆì‹œ:
1. íˆ¬ì, ì£¼ì‹, ì¶œì‹œ, ì†Œì†¡
2. ì‹¤ì , ê³„ì•½, ê°œë°œ, ì‹œì¥
""")
        
        return '\n'.join(prompt_parts)
    
    async def _parse_and_save_batch_results(self, batch_requests: List[BatchRequest], batch_response: str):
        """ë°°ì¹˜ ì‘ë‹µ íŒŒì‹± ë° ê²°ê³¼ ì €ì¥"""
        try:
            lines = batch_response.strip().split('\n')
            results_by_index = {}
            
            # ì‘ë‹µ íŒŒì‹±
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # "1. keyword1, keyword2, ..." í˜•íƒœ íŒŒì‹±
                if line[0].isdigit() and '.' in line:
                    parts = line.split('.', 1)
                    if len(parts) == 2:
                        index = int(parts[0]) - 1  # 0-based ì¸ë±ìŠ¤
                        keywords_str = parts[1].strip()
                        
                        if keywords_str:
                            selected_keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]
                            results_by_index[index] = selected_keywords
            
            # ê° ìš”ì²­ì— ëŒ€í•´ ê²°ê³¼ ì²˜ë¦¬
            async with self.result_lock:
                for i, request in enumerate(batch_requests):
                    try:
                        if i in results_by_index:
                            selected_keywords = results_by_index[i]
                            
                            # ì›ë³¸ í‚¤ì›Œë“œì™€ ë§¤ì¹­í•˜ì—¬ ë¹ˆë„ìˆ˜ í¬í•¨í•œ ê²°ê³¼ ìƒì„±
                            filtered_keywords = self._match_keywords_with_frequency(
                                selected_keywords, 
                                request.keywords_dict
                            )
                            
                            # ë¹ˆë„ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
                            sorted_keywords = sorted(filtered_keywords.items(), key=lambda x: x[1], reverse=True)
                            top_keywords = [k for k, v in sorted_keywords[:request.max_keywords]]
                            final_keywords = dict(sorted_keywords[:request.max_keywords])
                            
                            self.results[request.task_id] = BatchResult(
                                task_id=request.task_id,
                                status=TaskStatus.COMPLETED,
                                filtered_keywords=final_keywords,
                                top_keywords=top_keywords,
                                completed_at=datetime.now(),
                                original_request=request
                            )
                        else:
                            # í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                            self.results[request.task_id] = BatchResult(
                                task_id=request.task_id,
                                status=TaskStatus.FAILED,
                                error_message="AI ì‘ë‹µì—ì„œ í•´ë‹¹ ê¸°ì—…ì˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                                completed_at=datetime.now(),
                                original_request=request
                            )
                    
                    except Exception as e:
                        self.results[request.task_id] = BatchResult(
                            task_id=request.task_id,
                            status=TaskStatus.FAILED,
                            error_message=f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                            completed_at=datetime.now(),
                            original_request=request
                        )
        
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            await self._mark_batch_as_failed(batch_requests, f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    def _match_keywords_with_frequency(self, selected_keywords: List[str], original_keywords: Dict[str, int]) -> Dict[str, int]:
        """ì„ íƒëœ í‚¤ì›Œë“œë¥¼ ì›ë³¸ í‚¤ì›Œë“œì™€ ë§¤ì¹­í•˜ì—¬ ë¹ˆë„ìˆ˜ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        filtered_dict = {}
        matched_original_keywords = set()
        
        for selected in selected_keywords:
            matched = False
            
            # 1ë‹¨ê³„: ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
            if selected in original_keywords and selected not in matched_original_keywords:
                filtered_dict[selected] = original_keywords[selected]
                matched_original_keywords.add(selected)
                matched = True
            
            # 2ë‹¨ê³„: ë¶€ë¶„ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
            if not matched:
                for original_keyword in original_keywords:
                    if original_keyword not in matched_original_keywords:
                        if (selected in original_keyword or original_keyword in selected) and len(selected) >= 2:
                            filtered_dict[original_keyword] = original_keywords[original_keyword]
                            matched_original_keywords.add(original_keyword)
                            matched = True
                            break
        
        return filtered_dict
    
    async def _mark_batch_as_failed(self, batch_requests: List[BatchRequest], error_message: str):
        """ë°°ì¹˜ ìš”ì²­ë“¤ì„ ì‹¤íŒ¨ë¡œ í‘œì‹œ"""
        async with self.result_lock:
            for request in batch_requests:
                self.results[request.task_id] = BatchResult(
                    task_id=request.task_id,
                    status=TaskStatus.FAILED,
                    error_message=error_message,
                    completed_at=datetime.now(),
                    original_request=request
                )
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        return {
            **self.stats,
            "pending_requests": len(self.pending_requests),
            "stored_results": len(self.results),
            "is_running": self.is_running
        }
    
    async def cleanup_old_results(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ê²°ê³¼ ì •ë¦¬"""
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        async with self.result_lock:
            old_task_ids = [
                task_id for task_id, result in self.results.items()
                if result.completed_at and result.completed_at < cutoff_time
            ]
            
            for task_id in old_task_ids:
                del self.results[task_id]
            
            if old_task_ids:
                logger.info(f"ì˜¤ë˜ëœ ê²°ê³¼ {len(old_task_ids)}ê°œ ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ ë°°ì¹˜ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
batch_manager = None

def get_batch_manager() -> BatchKeywordManager:
    """ë°°ì¹˜ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global batch_manager
    if batch_manager is None:
        batch_manager = BatchKeywordManager()
    return batch_manager
