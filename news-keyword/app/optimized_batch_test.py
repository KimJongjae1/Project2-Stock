#!/usr/bin/env python3
"""
ê°œì„ ëœ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
ë™ì‹œ ìš”ì²­ì´ í•˜ë‚˜ì˜ ë°°ì¹˜ë¡œ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import time
import threading

BASE_URL = "http://localhost:8000"

def test_optimized_batching():
    """ê°œì„ ëœ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ê°œì„ ëœ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ê¸°ëŒ€ê°’: 3ê°œ ë™ì‹œ ìš”ì²­ â†’ 1ê°œ ë°°ì¹˜ â†’ 1ë²ˆ í† í° ì‚¬ìš©
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ëª©í‘œ:")
    print("  â€¢ 3ê°œ ê¸°ì—… ë™ì‹œ ìš”ì²­")
    print("  â€¢ 1ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬")
    print("  â€¢ 1ë²ˆ í† í° ì‚¬ìš© (ê°œë³„ ì²˜ë¦¬ ì‹œ 3ë²ˆ)")
    print()
    
    # 1. ì„œë²„ ìƒíƒœ í™•ì¸
    try:
        import requests
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code != 200:
            print("âŒ ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ. docker compose up ì‹¤í–‰ í•„ìš”")
            return
        print("âœ… ì„œë²„ ì—°ê²° í™•ì¸ë¨")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return
    
    # 2. ì´ˆê¸° í†µê³„ í™•ì¸
    try:
        response = requests.get(f"{BASE_URL}/batch/stats")
        initial_stats = response.json()
        print(f"ğŸ“Š ì´ˆê¸° í†µê³„:")
        print(f"  â€¢ ì´ ìš”ì²­: {initial_stats['total_requests']}")
        print(f"  â€¢ ì´ ë°°ì¹˜: {initial_stats['total_batches']}")
        print(f"  â€¢ í† í° ì ˆì•½: {initial_stats['total_tokens_saved']}")
        print()
    except Exception as e:
        print(f"âš ï¸ ì´ˆê¸° í†µê³„ í™•ì¸ ì‹¤íŒ¨: {e}")
        initial_stats = {}
    
    # 3. ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
    print("ğŸ”„ 3ê°œ ê¸°ì—… ë™ì‹œ ìš”ì²­ ì‹œì‘...")
    
    companies = ["ì‚¼ì„±ì „ì", "LGì „ì", "SKí•˜ì´ë‹‰ìŠ¤"]
    task_ids = []
    
    def submit_request(company):
        """ê°œë³„ ìš”ì²­ ì œì¶œ í•¨ìˆ˜"""
        try:
            payload = {
                "company_name": company,
                "start_date": "20200901",
                "end_date": "20200903"
            }
            
            response = requests.post(
                f"{BASE_URL}/extract-keywords-batch",
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                task_id = result["task_id"]
                print(f"  âœ… {company}: {task_id}")
                return task_id
            else:
                print(f"  âŒ {company}: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            print(f"  âŒ {company}: {e}")
            return None
    
    # ë™ì‹œ ìš”ì²­ ì‹¤í–‰ (ë§¤ìš° ë¹ ë¥¸ ì—°ì† ìš”ì²­)
    start_time = time.time()
    threads = []
    
    for company in companies:
        thread = threading.Thread(target=lambda c=company: task_ids.append(submit_request(c)))
        threads.append(thread)
        thread.start()
        # ê±°ì˜ ë™ì‹œì— ì‹¤í–‰ (10ms ê°„ê²©)
        time.sleep(0.01)
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for thread in threads:
        thread.join()
    
    # None ê°’ ì œê±°
    task_ids = [tid for tid in task_ids if tid is not None]
    submit_time = time.time() - start_time
    
    print(f"ğŸ“¤ ìš”ì²­ ì œì¶œ ì™„ë£Œ: {len(task_ids)}ê°œ ì‘ì—…, ì†Œìš” ì‹œê°„: {submit_time:.3f}ì´ˆ")
    print()
    
    if len(task_ids) != 3:
        print(f"âŒ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ì—… ìˆ˜: {len(task_ids)} (ì˜ˆìƒ: 3)")
        return
    
    # 4. ê²°ê³¼ ëŒ€ê¸°
    print("â³ ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ëŒ€ê¸° ì¤‘...")
    completed_results = []
    
    start_wait = time.time()
    timeout = 15  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
    
    while len(completed_results) < len(task_ids) and (time.time() - start_wait) < timeout:
        for i, task_id in enumerate(task_ids):
            if i < len(completed_results):
                continue  # ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…
                
            try:
                response = requests.get(f"{BASE_URL}/task/{task_id}/result")
                if response.status_code == 200:
                    result = response.json()
                    
                    if result["status"] in ["completed", "failed"]:
                        completed_results.append(result)
                        company = companies[i]
                        
                        if result["status"] == "completed":
                            keyword_count = len(result["data"]["filtered_keywords"])
                            print(f"  âœ… {company}: {keyword_count}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
                        else:
                            print(f"  âŒ {company}: {result.get('error', 'ì²˜ë¦¬ ì‹¤íŒ¨')}")
            except Exception as e:
                print(f"  âš ï¸ {companies[i]} ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        if len(completed_results) < len(task_ids):
            time.sleep(0.5)
    
    processing_time = time.time() - start_wait
    print(f"â±ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.3f}ì´ˆ")
    print()
    
    # 5. ìµœì¢… í†µê³„ í™•ì¸
    try:
        response = requests.get(f"{BASE_URL}/batch/stats")
        final_stats = response.json()
        
        print("ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"  â€¢ ì´ ìš”ì²­: {final_stats['total_requests']}")
        print(f"  â€¢ ì´ ë°°ì¹˜: {final_stats['total_batches']}")
        print(f"  â€¢ í† í° ì ˆì•½: {final_stats['total_tokens_saved']}")
        print(f"  â€¢ í‰ê·  ë°°ì¹˜ í¬ê¸°: {final_stats['average_batch_size']:.1f}")
        print(f"  â€¢ ëŒ€ê¸° ì¤‘ ìš”ì²­: {final_stats['pending_requests']}")
        print()
        
        # ì¦ê°€ëŸ‰ ê³„ì‚°
        if initial_stats:
            new_requests = final_stats['total_requests'] - initial_stats.get('total_requests', 0)
            new_batches = final_stats['total_batches'] - initial_stats.get('total_batches', 0)
            new_tokens_saved = final_stats['total_tokens_saved'] - initial_stats.get('total_tokens_saved', 0)
            
            print("ğŸ“ˆ ì´ë²ˆ í…ŒìŠ¤íŠ¸ ì¦ê°€ëŸ‰:")
            print(f"  â€¢ ìƒˆ ìš”ì²­: +{new_requests}")
            print(f"  â€¢ ìƒˆ ë°°ì¹˜: +{new_batches}")
            print(f"  â€¢ ì¶”ê°€ í† í° ì ˆì•½: +{new_tokens_saved}")
            print()
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            if new_requests == 3 and new_batches == 1:
                print("ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì„±ê³µ!")
                print("  âœ… 3ê°œ ìš”ì²­ì´ 1ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬ë¨")
                print(f"  âœ… í† í° ì ˆì•½: {new_tokens_saved} (ì˜ˆìƒ: 1000)")
                efficiency = ((3 - new_batches) / 3) * 100
                print(f"  âœ… íš¨ìœ¨ì„±: {efficiency:.1f}% í† í° ì ˆì•½")
            else:
                print("âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ë¶€ë¶„ ì„±ê³µ")
                print(f"  â€¢ 3ê°œ ìš”ì²­ â†’ {new_batches}ê°œ ë°°ì¹˜")
                if new_batches > 1:
                    print("  â€¢ ê°œì„  í•„ìš”: ëª¨ë“  ìš”ì²­ì´ í•˜ë‚˜ì˜ ë°°ì¹˜ë¡œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ")
                else:
                    print("  â€¢ ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•¨")
        
    except Exception as e:
        print(f"âŒ ìµœì¢… í†µê³„ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    print("=" * 60)
    print("ğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    test_optimized_batching()
