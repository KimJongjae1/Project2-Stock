#!/usr/bin/env python3
"""
í†µí•©ëœ ë°°ì¹˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
S3ì—ì„œ CSV íŒŒì¼ì„ ì½ì–´ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ë°°ì¹˜ ì²˜ë¦¬í•˜ëŠ” ì „ì²´ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import asyncio
import time
import requests
import json
from typing import List, Dict

BASE_URL = "http://localhost:8888"

async def test_integrated_system():
    """í†µí•©ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ í†µí•©ëœ ë°°ì¹˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # 1. ì„œë²„ ìƒíƒœ í™•ì¸
    print("1ï¸âƒ£ ì„œë²„ ìƒíƒœ í™•ì¸...")
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code != 200:
            print("âŒ ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ. main.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        print("âœ… ì„œë²„ ì—°ê²° í™•ì¸ë¨")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return
    
    # 2. ë°°ì¹˜ í†µê³„ ì´ˆê¸° í™•ì¸
    print("\n2ï¸âƒ£ ì´ˆê¸° ë°°ì¹˜ í†µê³„ í™•ì¸...")
    try:
        response = requests.get(f"{BASE_URL}/batch/stats")
        initial_stats = response.json()
        print(f"ğŸ“Š ì´ˆê¸° í†µê³„:")
        print(f"  â€¢ ì´ ìš”ì²­: {initial_stats['stats']['total_requests']}")
        print(f"  â€¢ ì´ ë°°ì¹˜: {initial_stats['stats']['total_batches']}")
        print(f"  â€¢ í† í° ì ˆì•½: {initial_stats['stats']['total_tokens_saved']}")
    except Exception as e:
        print(f"âš ï¸ ì´ˆê¸° í†µê³„ í™•ì¸ ì‹¤íŒ¨: {e}")
        initial_stats = {}
    
    # 3. ë°°ì¹˜ ìš”ì²­ ì œì¶œ
    print("\n3ï¸âƒ£ ë°°ì¹˜ ìš”ì²­ ì œì¶œ...")
    companies = ["ì‚¼ì„±ì „ì", "LGì „ì", "SKí•˜ì´ë‹‰ìŠ¤"]
    task_ids = []
    
    for company in companies:
        try:
            payload = {
                "company_name": company,
                "start_date": "20200901",
                "end_date": "20200903",
                "top_keywords": 10
            }
            
            response = requests.post(
                f"{BASE_URL}/extract-keywords-batch",
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                task_id = result["task_id"]
                task_ids.append(task_id)
                print(f"  âœ… {company}: {task_id}")
            else:
                print(f"  âŒ {company}: HTTP {response.status_code}")
                print(f"      ì‘ë‹µ: {response.text}")
                
        except Exception as e:
            print(f"  âŒ {company}: {e}")
    
    if not task_ids:
        print("âŒ ëª¨ë“  ìš”ì²­ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“¤ ì´ {len(task_ids)}ê°œ ì‘ì—… ì œì¶œ ì™„ë£Œ")
    
    # 4. ê²°ê³¼ ëŒ€ê¸° ë° í™•ì¸
    print("\n4ï¸âƒ£ ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ëŒ€ê¸°...")
    completed_results = []
    timeout = 30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    start_wait = time.time()
    
    while len(completed_results) < len(task_ids) and (time.time() - start_wait) < timeout:
        for i, task_id in enumerate(task_ids):
            if i < len(completed_results):
                continue  # ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…
                
            try:
                response = requests.get(f"{BASE_URL}/task/{task_id}/result")
                if response.status_code == 200:
                    result = response.json()
                    
                    if result["status"] in ["completed", "failed"]:
                        completed_results.append(result)
                        company = companies[i]
                        
                        if result["status"] == "completed":
                            keyword_count = len(result["data"]["keywords"])
                            print(f"  âœ… {company}: {keyword_count}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
                            print(f"      ì›ë³¸: {result['data']['original_keyword_count']}ê°œ â†’ í•„í„°ë§: {result['data']['filtered_keyword_count']}ê°œ")
                        else:
                            print(f"  âŒ {company}: {result.get('error', 'ì²˜ë¦¬ ì‹¤íŒ¨')}")
            except Exception as e:
                print(f"  âš ï¸ {companies[i]} ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        if len(completed_results) < len(task_ids):
            await asyncio.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
    
    processing_time = time.time() - start_wait
    print(f"\nâ±ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.3f}ì´ˆ")
    
    # 5. ìµœì¢… í†µê³„ í™•ì¸
    print("\n5ï¸âƒ£ ìµœì¢… ë°°ì¹˜ í†µê³„ í™•ì¸...")
    try:
        response = requests.get(f"{BASE_URL}/batch/stats")
        final_stats = response.json()
        
        print(f"ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"  â€¢ ì´ ìš”ì²­: {final_stats['stats']['total_requests']}")
        print(f"  â€¢ ì´ ë°°ì¹˜: {final_stats['stats']['total_batches']}")
        print(f"  â€¢ í† í° ì ˆì•½: {final_stats['stats']['total_tokens_saved']}")
        print(f"  â€¢ í‰ê·  ë°°ì¹˜ í¬ê¸°: {final_stats['stats']['average_batch_size']:.1f}")
        print(f"  â€¢ ëŒ€ê¸° ì¤‘ ìš”ì²­: {final_stats['stats']['pending_requests']}")
        
        # ì¦ê°€ëŸ‰ ê³„ì‚°
        if initial_stats:
            new_requests = final_stats['stats']['total_requests'] - initial_stats['stats'].get('total_requests', 0)
            new_batches = final_stats['stats']['total_batches'] - initial_stats['stats'].get('total_batches', 0)
            new_tokens_saved = final_stats['stats']['total_tokens_saved'] - initial_stats['stats'].get('total_tokens_saved', 0)
            
            print(f"\nğŸ“ˆ ì´ë²ˆ í…ŒìŠ¤íŠ¸ ì¦ê°€ëŸ‰:")
            print(f"  â€¢ ìƒˆ ìš”ì²­: +{new_requests}")
            print(f"  â€¢ ìƒˆ ë°°ì¹˜: +{new_batches}")
            print(f"  â€¢ ì¶”ê°€ í† í° ì ˆì•½: +{new_tokens_saved}")
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            if new_requests == len(task_ids) and new_batches >= 1:
                print(f"\nğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì„±ê³µ!")
                print(f"  âœ… {len(task_ids)}ê°œ ìš”ì²­ì´ {new_batches}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬ë¨")
                print(f"  âœ… í† í° ì ˆì•½: {new_tokens_saved}")
                if new_batches == 1:
                    efficiency = ((len(task_ids) - new_batches) / len(task_ids)) * 100
                    print(f"  âœ… íš¨ìœ¨ì„±: {efficiency:.1f}% í† í° ì ˆì•½")
            else:
                print(f"\nâš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ë¶€ë¶„ ì„±ê³µ")
                print(f"  â€¢ {len(task_ids)}ê°œ ìš”ì²­ â†’ {new_batches}ê°œ ë°°ì¹˜")
    
    except Exception as e:
        print(f"âŒ ìµœì¢… í†µê³„ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

def test_individual_extraction():
    """ê°œë³„ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)"""
    print("\nğŸ” ê°œë³„ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)")
    print("-" * 40)
    
    try:
        payload = {
            "company_name": "ì‚¼ì„±ì „ì",
            "start_date": "20200901",
            "end_date": "20200903",
            "top_keywords": 10,
            "use_ai_filter": True
        }
        
        response = requests.post(
            f"{BASE_URL}/extract-keywords",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… ê°œë³„ ì¶”ì¶œ ì„±ê³µ:")
            print(f"  â€¢ íšŒì‚¬: {result['company_name']}")
            print(f"  â€¢ ì´ ë‰´ìŠ¤: {result['total_news_count']}ê°œ")
            print(f"  â€¢ í‚¤ì›Œë“œ: {len(result['keywords'])}ê°œ")
            print(f"  â€¢ AI í•„í„°ë§: {result['ai_filtered']}")
            if result['ai_filtered']:
                print(f"  â€¢ ì›ë³¸ â†’ í•„í„°ë§: {result['original_keyword_count']}ê°œ â†’ {result['filtered_keyword_count']}ê°œ")
        else:
            print(f"âŒ ê°œë³„ ì¶”ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}")
            print(f"    ì‘ë‹µ: {response.text}")
            
    except Exception as e:
        print(f"âŒ ê°œë³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    print("ğŸš€ í†µí•©ëœ ë°°ì¹˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ë‚´ìš©:")
    print("  1. ì„œë²„ ìƒíƒœ í™•ì¸")
    print("  2. ë°°ì¹˜ í†µê³„ í™•ì¸")
    print("  3. ì—¬ëŸ¬ ê¸°ì—… ë™ì‹œ ë°°ì¹˜ ìš”ì²­")
    print("  4. ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ëŒ€ê¸°")
    print("  5. í† í° ì ˆì•½ íš¨ê³¼ í™•ì¸")
    print("  6. ê°œë³„ ì¶”ì¶œê³¼ ë¹„êµ")
    print()
    
    # í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    asyncio.run(test_integrated_system())
    
    # ê°œë³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)
    test_individual_extraction()
    
    print("\nğŸ’¡ ì‚¬ìš©ë²•:")
    print("  1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼ ìƒì„±):")
    print("     - OPENAI_API_KEY: OpenAI API í‚¤")
    print("     - AWS_ACCESS_KEY_ID: AWS ì•¡ì„¸ìŠ¤ í‚¤")
    print("     - AWS_SECRET_ACCESS_KEY: AWS ì‹œí¬ë¦¿ í‚¤")
    print("     - AWS_SESSION_TOKEN: AWS ì„¸ì…˜ í† í° (ì„ íƒì‚¬í•­)")
    print("  2. main.py ì‹¤í–‰: python main.py")
    print("  3. ì´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: python integration_test.py")
