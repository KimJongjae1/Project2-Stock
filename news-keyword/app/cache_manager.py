#!/usr/bin/env python3
"""
SQLite ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ ìºì‹œ ë§¤ë‹ˆì €
ì‹œì‘ì¼ì, ëì¼ì, ê¸°ê´€ëª…ì„ ë³µí•© í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤.
"""

import sqlite3
import json
import os
import logging
from datetime import datetime
from typing import Optional, Dict, Any
import hashlib

logger = logging.getLogger(__name__)

class CacheManager:
    """SQLite ê¸°ë°˜ ìºì‹œ ë§¤ë‹ˆì €"""
    
    def __init__(self, db_path: str = "keyword_cache.db"):
        """
        ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            db_path: SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì´ˆê¸°í™”"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # í‚¤ì›Œë“œ ìºì‹œ í…Œì´ë¸” ìƒì„±
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS keyword_cache (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        cache_key TEXT UNIQUE NOT NULL,
                        company_name TEXT NOT NULL,
                        start_date TEXT NOT NULL,
                        end_date TEXT NOT NULL,
                        top_keywords INTEGER NOT NULL,
                        use_ai_filter BOOLEAN NOT NULL,
                        result_data TEXT NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        accessed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        access_count INTEGER DEFAULT 1
                    )
                """)
                
                # ì¸ë±ìŠ¤ ìƒì„± (ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ)
                cursor.execute("""
                    CREATE INDEX IF NOT EXISTS idx_cache_key ON keyword_cache(cache_key)
                """)
                cursor.execute("""
                    CREATE INDEX IF NOT EXISTS idx_company_date ON keyword_cache(company_name, start_date, end_date)
                """)
                
                conn.commit()
                logger.info(f"âœ… ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {self.db_path}")
                
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_cache_key(self, company_name: str, start_date: str, end_date: str, 
                           top_keywords: int, use_ai_filter: bool) -> str:
        """
        ìºì‹œ í‚¤ ìƒì„± (ë³µí•© í‚¤ì˜ í•´ì‹œê°’)
        
        Args:
            company_name: ê¸°ì—…ëª…
            start_date: ì‹œì‘ì¼ì
            end_date: ëì¼ì
            top_keywords: ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜
            use_ai_filter: AI í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ìºì‹œ í‚¤ (í•´ì‹œê°’)
        """
        key_string = f"{company_name}|{start_date}|{end_date}|{top_keywords}|{use_ai_filter}"
        return hashlib.md5(key_string.encode('utf-8')).hexdigest()
    
    def get_cached_result(self, company_name: str, start_date: str, end_date: str, 
                         top_keywords: int, use_ai_filter: bool) -> Optional[Dict[str, Any]]:
        """
        ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ
        
        Args:
            company_name: ê¸°ì—…ëª…
            start_date: ì‹œì‘ì¼ì
            end_date: ëì¼ì
            top_keywords: ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜
            use_ai_filter: AI í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ìºì‹œëœ ê²°ê³¼ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            cache_key = self._generate_cache_key(company_name, start_date, end_date, 
                                               top_keywords, use_ai_filter)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ìºì‹œ ì¡°íšŒ
                cursor.execute("""
                    SELECT result_data, access_count FROM keyword_cache 
                    WHERE cache_key = ?
                """, (cache_key,))
                
                result = cursor.fetchone()
                
                if result:
                    # ì ‘ê·¼ ì‹œê°„ ë° íšŸìˆ˜ ì—…ë°ì´íŠ¸
                    cursor.execute("""
                        UPDATE keyword_cache 
                        SET accessed_at = CURRENT_TIMESTAMP, access_count = access_count + 1
                        WHERE cache_key = ?
                    """, (cache_key,))
                    
                    conn.commit()
                    
                    # JSON ë°ì´í„° íŒŒì‹±
                    cached_data = json.loads(result[0])
                    access_count = result[1] + 1
                    
                    logger.info(f"ğŸ¯ ìºì‹œ íˆíŠ¸: {company_name} ({start_date}-{end_date}) - ì ‘ê·¼íšŸìˆ˜: {access_count}")
                    return cached_data
                else:
                    logger.info(f"âŒ ìºì‹œ ë¯¸ìŠ¤: {company_name} ({start_date}-{end_date})")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def save_result(self, company_name: str, start_date: str, end_date: str, 
                   top_keywords: int, use_ai_filter: bool, result_data: Dict[str, Any]) -> bool:
        """
        ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
        
        Args:
            company_name: ê¸°ì—…ëª…
            start_date: ì‹œì‘ì¼ì
            end_date: ëì¼ì
            top_keywords: ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜
            use_ai_filter: AI í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
            result_data: ì €ì¥í•  ê²°ê³¼ ë°ì´í„°
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            cache_key = self._generate_cache_key(company_name, start_date, end_date, 
                                               top_keywords, use_ai_filter)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # JSON ë°ì´í„° ì§ë ¬í™”
                json_data = json.dumps(result_data, ensure_ascii=False, indent=2)
                
                # ìºì‹œ ì €ì¥ (ì¤‘ë³µ ì‹œ ë¬´ì‹œ)
                cursor.execute("""
                    INSERT OR IGNORE INTO keyword_cache 
                    (cache_key, company_name, start_date, end_date, top_keywords, 
                     use_ai_filter, result_data, created_at, accessed_at, access_count)
                    VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, 1)
                """, (cache_key, company_name, start_date, end_date, top_keywords, 
                      use_ai_filter, json_data))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    logger.info(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì™„ë£Œ: {company_name} ({start_date}-{end_date})")
                    return True
                else:
                    logger.info(f"âš ï¸ ìºì‹œ ì´ë¯¸ ì¡´ì¬: {company_name} ({start_date}-{end_date})")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        ìºì‹œ í†µê³„ ì •ë³´ ì¡°íšŒ
        
        Returns:
            ìºì‹œ í†µê³„ ë°ì´í„°
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ì „ì²´ ìºì‹œ ê°œìˆ˜
                cursor.execute("SELECT COUNT(*) FROM keyword_cache")
                total_caches = cursor.fetchone()[0]
                
                # ì´ ì ‘ê·¼ íšŸìˆ˜
                cursor.execute("SELECT SUM(access_count) FROM keyword_cache")
                total_accesses = cursor.fetchone()[0] or 0
                
                # ìµœê·¼ ìƒì„±ëœ ìºì‹œ (7ì¼ ì´ë‚´)
                cursor.execute("""
                    SELECT COUNT(*) FROM keyword_cache 
                    WHERE created_at >= datetime('now', '-7 days')
                """)
                recent_caches = cursor.fetchone()[0]
                
                # ê°€ì¥ ë§ì´ ì ‘ê·¼ëœ ìºì‹œ Top 5
                cursor.execute("""
                    SELECT company_name, start_date, end_date, access_count 
                    FROM keyword_cache 
                    ORDER BY access_count DESC 
                    LIMIT 5
                """)
                top_caches = cursor.fetchall()
                
                return {
                    "total_caches": total_caches,
                    "total_accesses": total_accesses,
                    "recent_caches_7days": recent_caches,
                    "top_accessed_caches": [
                        {
                            "company": row[0],
                            "period": f"{row[1]}-{row[2]}",
                            "access_count": row[3]
                        }
                        for row in top_caches
                    ]
                }
                
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def clear_old_cache(self, days: int = 30) -> int:
        """
        ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ
        
        Args:
            days: ì‚­ì œí•  ìºì‹œì˜ ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30ì¼)
            
        Returns:
            ì‚­ì œëœ ìºì‹œ ê°œìˆ˜
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ì‚­ì œ ì „ ê°œìˆ˜ í™•ì¸
                cursor.execute("""
                    SELECT COUNT(*) FROM keyword_cache 
                    WHERE created_at < datetime('now', '-{} days')
                """.format(days))
                
                delete_count = cursor.fetchone()[0]
                
                # ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ
                cursor.execute("""
                    DELETE FROM keyword_cache 
                    WHERE created_at < datetime('now', '-{} days')
                """.format(days))
                
                conn.commit()
                
                logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ ì™„ë£Œ: {delete_count}ê°œ (>{days}ì¼)")
                return delete_count
                
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return 0
    
    def cleanup(self):
        """ìºì‹œ ë§¤ë‹ˆì € ì •ë¦¬"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë¦¬
            if os.path.exists(self.db_path):
                logger.info(f"âœ… ìºì‹œ ë§¤ë‹ˆì € ì •ë¦¬ ì™„ë£Œ: {self.db_path}")
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ë§¤ë‹ˆì € ì •ë¦¬ ì‹¤íŒ¨: {e}")
